from scipy import signal
import matplotlib.pyplot as plt
import numpy as np
from numpy import argmax
import time
import copy
import os
import json

"""
# The module is to generate a set of simulated spectrums

## spectrum data can be generated by these steps below
    - add baseline
    - smoothing (butterworth filter)
    - add peaks
    - add noise

"""

#バターワースフィルタ（ローパス）
def add_butter_worth_filter(x, sampling_rate, fp, fs, gpass, gstop, curve="linear"):
    x=copy.copy(x)
    """
    ## Butterworth filter (lowpass filter) fuction
    
    ## Parameters
        - sampling_rate: 波形のサンプリングレート
        - fp: 通過域端周波数[Hz]
        - fs: 阻止域端周波数[Hz]
        - gpass: 通過域端最大損失[dB]
        - gstop: 阻止域端最小損失[dB]
        - curve: 減衰関数  
            - linear: 線形減衰
    """
    fn = sampling_rate / 2                        #ナイキスト周波数
    wp = fp / fn                                  #ナイキスト周波数で通過域端周波数を正規化
    ws = fs / fn                                  #ナイキスト周波数で阻止域端周波数を正規化
    N, Wn = signal.buttord(wp, ws, gpass, gstop)  #オーダーとバターワースの正規化周波数を計算
    if N < 0:
        N = 0
    b, a = signal.butter(N, Wn, "low")            #フィルタ伝達関数の分子と分母を計算
    if a.any()<2:
        a=2
    if type(a) == int or len(a) < 2:
        a_temp = copy.copy(a)
        a = np.zeros((2))
        a[0:2] = a_temp
    y = signal.filtfilt(b, a, x)                  #信号に対してフィルタをかける
    return y                                      #フィルタ後の信号を返す

def add_baseline(width, baseline_height, std):
    baseline = np.random.normal(baseline_height, std, (width))
    # np_lowpassed = lowpass(np_rand,40, 1, 2, 3, 40)
    return baseline

def add_noise(baseline, signal, nsr):
    '''
    ## function which adds noise on signal
    
    ## Parameters
        - baseline: baseline sequence data
        - signal: signal sequence data
        - nsr: noise signal ratio (noise/signal)
    '''
    max_pos = argmax(signal,axis=0)
    signal_amp = signal[max_pos] - baseline[max_pos]
    noise_scale = nsr * signal_amp
    np_noise = np.random.normal(0, noise_scale, (len(signal)))
    return signal+np_noise

def gauss(x, pos, amp=1, sigma=1):
    return amp * np.exp(-(x - pos)**2 / (2*sigma**2))

def add_peak(signal, label, pos, amp=1, sigma=1, label_ci=1):
    signal = copy.copy(signal)
    width = len(signal)
    height = np.max(signal, axis=0).astype(np.float32)
    n_pos = int(pos * width)
    n_sigma = int(sigma*width)
    amp = height*amp
    n_scale = width
    peak = gauss(np.arange(0, n_scale, 1), n_pos, amp, n_sigma)
    signal += peak
    if label_ci > 3:
        label_ci = 3
    label[n_pos-n_sigma*label_ci: n_pos+n_sigma*label_ci] = 1
    return signal, label

def add_peaks(base_signal, pos_list, a_list, sigma_list, label_ci=1):
    """
    ## Function which adds the optional number of peaks on the base signal
    
    ## Parametes
        - base_signal: base signal
        - pos_list: list of the center positions of each peaks
        - a_list: list of the amplitudes of each peaks
        - sigma_list: list of the sigma(σ) of each peaks
        - label_ci: confidence interval (as peak bandwidth) => label data
    """
    signal = copy.copy(base_signal)
    pos_list = np.array(pos_list)
    a_list = np.array(a_list)
    sigma_list = np.array(sigma_list)
    label = np.zeros(len(signal))
    for i, _ in enumerate(pos_list):
        signal, label = add_peak(signal, label, pos_list[i], a_list[i], sigma_list[i], label_ci=label_ci)
    return signal, label

def gen_dataset(spectrum_num, width, dataset_dir, label_ci, baseline_height_range, std_range, 
                sprate_range, fp_range, fs_range, gpass_range, gstop_range, peak_num_range, pos_range,
                amp_range, sigma_range, nsr_range, seed_type="time", seed=2, smoothing_curve="linear"):
    if not os.path.exists(dataset_dir):
        os.makedirs(dataset_dir, exist_ok=True)
    
    if seed_type == "time":
        np.random.seed(int(time.time()))
    elif seed_type == "fix" and type(seed_type) == int:
        np.random.seed(seed)
    else:
        np.random.seed(2)
    for i in range(spectrum_num):
        try:
            rnd = np.random.rand(12)
            
            baseline_height = baseline_height_range[0] + rnd[0]*(baseline_height_range[1]-baseline_height_range[0])
            std = std_range[0] + rnd[1]*(std_range[1] - std_range[0])
            sampling_rate = sprate_range[0] + rnd[2]*(sprate_range[1]-sprate_range[0])
            fp = fp_range[0] + rnd[3]*(fp_range[1]-fp_range[0])
            fs = fs_range[0] + rnd[4]*(fs_range[1]-fs_range[0])
            gpass = gpass_range[0] + rnd[5]*(gpass_range[1]-gpass_range[0])
            gstop = gstop_range[0] + rnd[6]*(gstop_range[1]-gstop_range[0])
            peak_num = np.random.randint(peak_num_range[0], peak_num_range[1])
            pos_list = np.random.rand(peak_num)
            pos_list = pos_range[0] + pos_list*(pos_range[1]-pos_range[0])
            amp_list = np.random.rand(peak_num)
            amp_list = amp_range[0] + amp_list*(amp_range[1]-amp_range[0])
            sigma_list = np.random.rand(peak_num)
            sigma_list = sigma_range[0] + sigma_list*(sigma_range[1] - sigma_range[0])
            nsr = nsr_range[0] + rnd[7]*(nsr_range[1]-nsr_range[0])
            
            baseline = add_baseline(width, baseline_height, std)
            baseline = add_butter_worth_filter(baseline, sampling_rate, fp, fs, gpass, gstop, smoothing_curve)
            signal, label = add_peaks(baseline, pos_list, amp_list, sigma_list, label_ci)
            signal = add_noise(baseline, signal, nsr)
            
            np.savez(dataset_dir+f"signal{i}", x=signal, y=label)
            
            del_list = [pos_list, amp_list, sigma_list]
            del rnd, baseline, signal, label, del_list
        except:
            pass
    return

def gen_dataset_v2(dict:dict):
    spectrum_num = dict["spectrum_num"]
    width = dict["width"]
    label_ci = dict["label_ci"]
    baseline_height_range = dict["baseline_height_range"]
    std_range = dict["std_range"]
    sprate_range = dict["sprate_range"]
    fp_range = dict["fp_range"]
    fs_range = dict["fs_range"]
    gpass_range = dict["gpass_range"]
    gstop_range = dict["gstop_range"]
    peak_num_range = dict["peak_num_range"]
    pos_range = dict["pos_range"]
    amp_range = dict["amp_range"]
    sigma_range = dict["sigma_range"]
    nsr_range = dict["nsr_range"]
    dataset_id = dict["dataset_id"]
    dataset_dir_root = dict["dataset_dir"]
    dataset_dir = dataset_dir_root+f"/{dataset_id}/"
    
    try:
        seed_type = dict["seed_type"]
    except:
        seed_type = "time"
    try:
        smoothing_curve = dict["smoothing_curve"]
    except:
        smoothing_curve = "linear"
    
    if not os.path.exists(dataset_dir):
        os.makedirs(dataset_dir, exist_ok=True)
    
    if seed_type == "time":
        np.random.seed(int(time.time()))
    elif seed_type == "fix":
        try:
            seed = dict["seed"]
            np.random.seed(seed)
        except:
            np.random.seed(2)
    
    for i in range(spectrum_num):
        try:
            rnd = np.random.rand(12)
            
            baseline_height = baseline_height_range[0] + rnd[0]*(baseline_height_range[1]-baseline_height_range[0])
            std = std_range[0] + rnd[1]*(std_range[1] - std_range[0])
            sampling_rate = sprate_range[0] + rnd[2]*(sprate_range[1]-sprate_range[0])
            fp = fp_range[0] + rnd[3]*(fp_range[1]-fp_range[0])
            fs = fs_range[0] + rnd[4]*(fs_range[1]-fs_range[0])
            gpass = gpass_range[0] + rnd[5]*(gpass_range[1]-gpass_range[0])
            gstop = gstop_range[0] + rnd[6]*(gstop_range[1]-gstop_range[0])
            peak_num = np.random.randint(peak_num_range[0], peak_num_range[1])
            pos_list = np.random.rand(peak_num)
            pos_list = pos_range[0] + pos_list*(pos_range[1]-pos_range[0])
            amp_list = np.random.rand(peak_num)
            amp_list = amp_range[0] + amp_list*(amp_range[1]-amp_range[0])
            sigma_list = np.random.rand(peak_num)
            sigma_list = sigma_range[0] + sigma_list*(sigma_range[1] - sigma_range[0])
            nsr = nsr_range[0] + rnd[7]*(nsr_range[1]-nsr_range[0])
            
            baseline = add_baseline(width, baseline_height, std)
            baseline = add_butter_worth_filter(baseline, sampling_rate, fp, fs, gpass, gstop, smoothing_curve)
            signal, label = add_peaks(baseline, pos_list, amp_list, sigma_list, label_ci)
            signal = add_noise(baseline, signal, nsr)
            
            np.savez(dataset_dir+f"signal{i}", x=signal, y=label)
            
            del_list = [pos_list, amp_list, sigma_list]
            del rnd, baseline, signal, label, del_list
        except:
            pass
    with open(dataset_dir_root+f"/config_{dataset_id}.json", 'w') as f:
        json.dump(dict, f, indent=4)
    return
    


if __name__ == "__main__":
    
    width=2000
    dataset_dir = "../../data/dataset/"

    gen_dataset(1000, 2000, dataset_dir, 1, [10, 20], [5, 10], [1, 10], [0.1, 0.2], [1, 2], [0.1, 1.0], [10, 100], 
                [1, 3], [0.01, 0.99], [0.5, 2.0], [0.01, 0.1], [0.01, 0.05], seed_type="time")
    filelist = os.listdir(dataset_dir)[:1000]
    
    signal = []
    label =[]
    
    check_num = 20
    for h in range(check_num):
        j = k =0
        files = filelist[h*8:(h+1)*8]
        print(files)
        fig,axs = plt.subplots(2,4, figsize=(10,6))
        for i,file in enumerate(files):
            data = np.load(dataset_dir+file)
            signal.append(data["x"])
            label.append(data["y"])
            label_y = data["y"]
            
            if k > 0 and k %4 == 0:
                j+=1
                k =0
            axs[j,k].plot(range(0, width, 1), data["x"])
            axs[j,k].plot(np.where(label_y > 0)[0], data["x"][np.where(label_y > 0)], "x")    
            
            k+=1
        # fig.canvas.draw()
        # fig.canvas.flush_events()
        # plt.pause(1)
        plt.show()
        # fig.clear()
        plt.close()
